{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('baseline_submission_cld2.csv')\n",
    "pred = df['Answer']\n",
    "\n",
    "df = pd.read_csv('baseline_submission_cld.csv')\n",
    "gt = df['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'average_precision': 0.7741511377532191, 'average_recall': 0.6344903834248791, 'average_f1_score': 0.6680342766767629}\n"
     ]
    }
   ],
   "source": [
    "def calculate_f1_score(true_sentence, predicted_sentence, sum_mode=True):\n",
    "\n",
    "    #공백 제거\n",
    "    true_sentence = ''.join(true_sentence.split())\n",
    "    predicted_sentence = ''.join(predicted_sentence.split())\n",
    "    \n",
    "    true_counter = Counter(true_sentence)\n",
    "    predicted_counter = Counter(predicted_sentence)\n",
    "\n",
    "    #문자가 등장한 개수도 고려\n",
    "    if sum_mode:\n",
    "        true_positive = sum((true_counter & predicted_counter).values())\n",
    "        predicted_positive = sum(predicted_counter.values())\n",
    "        actual_positive = sum(true_counter.values())\n",
    "\n",
    "    #문자 자체가 있는 것에 focus를 맞춤\n",
    "    else:\n",
    "        true_positive = len((true_counter & predicted_counter).values())\n",
    "        predicted_positive = len(predicted_counter.values())\n",
    "        actual_positive = len(true_counter.values())\n",
    "\n",
    "    #f1 score 계산\n",
    "    precision = true_positive / predicted_positive if predicted_positive > 0 else 0\n",
    "    recall = true_positive / actual_positive if actual_positive > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def calculate_average_f1_score(true_sentences, predicted_sentences):\n",
    "    \n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1_score = 0\n",
    "    \n",
    "    for true_sentence, predicted_sentence in zip(true_sentences, predicted_sentences):\n",
    "        precision, recall, f1_score = calculate_f1_score(true_sentence, predicted_sentence)\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f1_score += f1_score\n",
    "    \n",
    "    avg_precision = total_precision / len(true_sentences)\n",
    "    avg_recall = total_recall / len(true_sentences)\n",
    "    avg_f1_score = total_f1_score / len(true_sentences)\n",
    "    \n",
    "    return {\n",
    "        'average_precision': avg_precision,\n",
    "        'average_recall': avg_recall,\n",
    "        'average_f1_score': avg_f1_score\n",
    "    }\n",
    "\n",
    "result = calculate_average_f1_score(gt, pred)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average_precision': 0.045348488712451056,\n",
       " 'average_recall': 0.05482170578524533,\n",
       " 'average_f1_score': 0.043404681577121636}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'average_precision': 0.7836387679806227, 'average_recall': 0.6952563576881929, 'average_f1_score': 0.6982555298335544} # gpt, cld\n",
    "{'average_precision': 0.8040557531835396, 'average_recall': 0.4980727124424879, 'average_f1_score': 0.5809782681602945}# lora 9\n",
    "{'average_precision': 0.7510245483278776, 'average_recall': 0.49223857025889495, 'average_f1_score': 0.555715908120697} # lora 10\n",
    "{'average_precision': 0.809970184368611, 'average_recall': 0.49179135084510883, 'average_f1_score': 0.5797616831233486} # lora 11\n",
    "{'average_precision': 0.8240925839987387, 'average_recall': 0.5305136610459819, 'average_f1_score': 0.6101767801985607}# lora 12\n",
    "{'average_precision': 0.8140793959463452, 'average_recall': 0.534529428521605, 'average_f1_score': 0.6105656555667893} # lora 13\n",
    "{'average_precision': 0.7993750484461434, 'average_recall': 0.5283969240877573, 'average_f1_score': 0.6031556489189079} # lora 14\n",
    "{'average_precision': 0.772951001848491, 'average_recall': 0.4303243240872776, 'average_f1_score': 0.5127208078484311} # lora 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
